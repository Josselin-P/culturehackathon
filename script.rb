element
element[]
element[:href]
@breve
edit_breve_url(@breve)
edit_breve_path(@breve)
exit all
exit-all
element
breve_path(@breve)
exit-all
element
element[:data-method]
element[:#{data-}method]
  exit-all
element[:'data-method']
exit-all
element
element[:href]
exit-all
element = find_by_id("edit_breve_#{@breve.id}")[:href]
element
exit-all
element
exit-all
signed_in?
user
exit-all
User.all
exit-mall
User.all
exit-all
User.all
exit-all
User.all
exit-all
User.all
exit-all
authorships
authorship
authorship.user
authorship.author
authorship.breve
maBreve = authorship.breve
breve.authors
exit-all
authorship
exit-all
authorship
exit
exit-all
authorship
exit-all
author
author.authorships
breve
breve.authorships
Authorship.new(author: author, breve: breve)
breve.authorship.build(author_id: author.id)
breve.authorships.build(author_id: author.id)
exit-all
authorship
exit
exit-all
author
author.authorships
exit-all
author
author.authorships
authorship
authorship.breve
authorship.author
exit-all
authorship
authorship.author
exit-all
oships
exit-all
author
author.authorships
exit-all
author
author.authorships
oship = author.authorships.dup
oship
author.destroy
author
oship
exit-all
author
authorship
author.authorships
exit-all
author.authorships
authorship
author.authorship
author.authorships
exit-all
oships
exit-all
oships
breve
breve.authorships
authorship
breve.authorships
authorship.breve
authorship.breve.authorships
authorship.breve.authors
breve.authorships.build(author_id: author.id)
authorships
Authorship.all
User.all
authorship.save
breve.authorships.save(author_id: author.id)
breve.authorships.create(author_id: author.id)
breve.authorships.create(author_id: 2)
breve.authorships
author.authorships
exit-all
authorship
author.authorships
breve.authorships
User.all
Breve.all
authorship.save
Authorship.all
Breve.first.authorships
berve.authorships
breve.authorships
breve.reload
breve.authorships
exit-all
Breve.all
exit-all
nearby_breves
exit-all
result
result[0]
result[1]
exit-all
result
result[0]
result[1]
exit-all
result
exit-all
result
exit-all
result
breve
exit-all
nearby_breves
exit-all
ordered
Breve.all
exit-all
essai
essai.elements
essai.@elements
exit-all
essai
essai.text
exit-all
essai
exit-all
essai
exit-all
essai
exit-all
essai
exit-all
essai
exit-all
essai
exit-all
essai
exit-all
essai
essai[0].text
exit-all
breves_array
nearby_breves
ordered
exit-all
breves_array
nearby_breves
coordinattes
coordinates
distance
Breve.near(coordinates, distance)
exit-all
ordered
exit-all
nearby_breves
breves_array
exit-all
ordered_breves
exit-all
nearby_breves
ordered_breves
exit-all
user
current_user
@current_user
Session.all
User.all
exit-all
User.all
exit-all
User.all
exit-all
User.all
exit-all
User.all
exit-all
user
standard?
exit-all
user
exit-all
user
exit-all
user
exit-all
user
exit-all
user
exit-all
user
exit-all
user
exit-all
user
exit-all
user
exit-all
user
exit-all
user
exit-all
user
exit-all
user
exit-all
user
exit-all
user
exit-all
user
exit-all
user
exit-all
user
exit-all
user
exit-all
user
exit-all
user
exit-all
user
exit-all
user
exit-all
user
exit-all
user
exit-all
user
exit-all
user
exit-all
user
exit-all
@new_user_2
exit-all
@new_user_2
exit-all
user
exit-all
user
exit-all
user
exit-all
user
exit-all
user
exit-all
user
can? :read, :user
can? :read, :breve
can? :create, :breve
can :update, :breve
can? :update, :breve
exit-all
can? :destroy, :breve
can
exit-all
request.referer
URI.split(request.referer)
URI.split(request.referer).path
URI.path
URI.parse(request.referer).path
URI.parse(request.referer).path.split
URI.parse(request.referer).path.split('/')
URI.parse(request.referer).path.split('/').last
exit
exit-all
version
version.history_to_s
@breve.versions.last.history_to_s
@breve.versions.first.history_to_s
exit
@center
@location
exit
@center
exit
Breve
Breve.all
Breve.fist
Breve.first
Breve.where("photo IS NOT NULL")
Breve.where("photo IS NOT NULL").all
Breve.where("photo_file_name IS NOT NULL")
exit
changeset
version
version.changeset
exit
version
version.changeset
exit
version
version.changeset
exit
version
version.changeste
version.changeset
version
exit
@content
@content.first
@content.first.changeset
exit
datasetPage.css('.publi time')
datasetPage.css('.publi time')['datetime']
datasetPage.css('.publi time')
cd _
ls
self
sel.class
sef
self.class
first
first.attributes
first.attributes.datetime
first.attributes['datetime']
first.attributes['datetime'].value
exit
!!!
datasetPage.css('like_nav_ul a')
!!!
datasetPage.css('.like_nav_ul a')
datasetPage.css('.rechResul_MotsCles .like_nav_ul a')
datasetPage.css('.rechResul_MotsCles .like_nav_ul a').first
!!!
datasetPage.css('.rechResul_MotsCles .like_nav_ul a')
datasetPage.css('.rechResul_MotsCles .like_nav_ul a').first
datasetPage.css('.rechResul_MotsCles .like_nav_ul a').first.text
!!!
link
index
!!!
index
!!!
index
exit
!!!
datasetsInfo
exit
!!!
datasetsInfo
!!!
datasetsInfo
!!!
datasetPage.css('.Prtg_Aside_Bloc .download a')
datasetPage.css('.Prtg_Aside_Bloc .download a').attributes.href.value
datasetPage.css('.Prtg_Aside_Bloc .download a').attributes
datasetPage.css('.Prtg_Aside_Bloc .download a').first
datasetPage.css('.Prtg_Aside_Bloc .download a').first.attributes
datasetPage.css('.Prtg_Aside_Bloc .download a').attributes['href']
datasetPage.css('.Prtg_Aside_Bloc .download a').first.attributes['href']
!!!
datasetsInfo
!!!
datasetsInfo
!!!
datasetsInfo
!!!
datasetsInfo
cd datasetsInfo
self
!!!
datasetsInfo
!!
!!!
datasetsInfo
exit
datasetsInfo
datasetsInfo.first
datasetsInfo[2]
datasetsInfo.length
datasetsInfo[1]
datasetsInfo[8]
datasetsInfo[7]
!!!
datasetsInfo[7]
datasetsInfo[8]
exit
datasetsInfo.length
!!!
datasetsInfo.length
datasetsInfo.last
!!!
self
i
index
datasetPage
!!!
e
datasetPage
!!!
e
datasetInfo[:publication_date]
datasetPage.css('.Prtg_Aside_Bloc .download a')
!!!
datasetsInfo.length
datasetsInfo.last
!!!
datasetsInfo.last
datasetsInfo.last[:period]
datasetsInfo.last[:period].split('du ')
datasetsInfo.last[:period].split(' ')
!!!
datasetsInfo.last
!!!
edit
edit get
!!!
datasetsInfo
continue
!!!
dataset.download_link
!!!
next
read_bytes
finish
continue
dataset.content
exit
!!!
datasetsInfo
!!!
datasetsInfo
!!!
next
continue
!!!
continue
exit
continue
dataset
dataset.first
datasetsInfo
!!!
continue
dataset
dataset.content
!!!
index
next
step
next
step
whereami
pry-backtrace
finish
next
dest
next
dest
nxt
next
read_bytes
dest
next
@rbuf
next
@rbuf
next
@rbuf
!!!
continue
cd-cause
continue
!!!
continue
!!!
continue
line
buffer
continue
line
buffer
!!!
continue
line
buffer
!!!
continue
buffer
line
continue
dataset
exit
!!!
continue
line
line.gsub(/(?<!^|,)"(?!,|$)/,"'")
line.gsub(/(?<!^|,\)"(?!,|$)/,"'")
line.gsub(/(?<!^|,)"(?!,|$)/,"'")
line.gsub(/"/,"'")
!!!
continue
dataset
!!!
continue
buffer
!!!
datasetsInfo
buffer
!!!
buffer
buffer2 = buffer.encode("UTF-8", :invalid => :replace, :undef => :replace, :replace => "?")
buffer2
buffer2.to_json
!!!
buffer
my_hash = JSON.parse(buffer)
!!!
buffer
!!!
continue
buffer
!!!
buffer
!!!
buffer
JSON.parse(buffer)
!!!
dataset.download_link
open(_)
open(_).read
CSV.open(open(dataset.download_link)).readlines
CSV.open(open(dataset.download_link).read).readlines
CSV.open(open(dataset.download_link).read, col_sep: '\t').readlines
CSV.open(open(dataset.download_link).read, col_sep: '\t').readlines.first
CSV.open(open(dataset.download_link)).readlines
dataset.download_link
CSV.read('data.csv')
CSV.read('data.csv', col_sep: "\t", encoding: "US-ASCII")
CSV.read('data.csv', col_sep: "\t", encoding: "ASCII")
CSV.read('data.csv', col_sep: "\t", encoding: "ISO8859-1")
CSV.read('data.csv', col_sep: "\t", encoding: "ISO8859-1").to_json
JSON.parse(CSV.read('data.csv', col_sep: "\t", encoding: "ISO8859-1").to_json)
CSV.read('data.csv', col_sep: "\t", encoding: "ISO8859-1", headers: true)
cd CSV.read('data.csv', col_sep: "\t", encoding: "ISO8859-1", headers: true)
ls
headers
cd ..
csv = CSV.read('data.csv', col_sep: "\t", encoding: "ISO8859-1", headers: true)
csv.headers
keys = csv.headers
keys
csv.delete(1)
csv
csv.first
csv[2]
csv[2].to_json
data = csv.map { |v| Hash[keys.zip(v)] }
data.to_json
data = csv.map { |v| Hash[keys.zip(v[1])] }
csv.first
csv.first.to_a
data = csv.map { |v| Hash[keys.zip(v.to_a[1])] }
csv.first.to_a
data = csv.map { |v| Hash[keys.zip(v.to_a[1])] }
csv.first
csv.first.to_a
csv.first.to_a.to_json
JSON.parse(csv.first.to_a.to_json)
data = csv.map { |v| Hash[keys.zip(v.to_a[1])] }
csv.first
cd csv.first
self.class
ls
to_hash
cd /
data = csv.map { |v| Hash[keys.zip(v.to_hash)] }
data = csv.map { |v| Hash[keys.zip(v[1].to_hash)] }
cd csv.first
ls
to_hash
cd ..
csv.map { |r| r.to_hash }
csv.map { |r| r.to_hash }.to_juson
csv.map { |r| r.to_hash }.to_json
cd csv.first
ls
self
csv = CSV.read('data.csv', encoding: "ISO8859-1", headers: true)
csv = CSV.read('data.csv', encoding: "ISO8859-1", headers: true).first
csv = CSV.read('data.csv', col_sep: "\t", encoding: "ISO8859-1", headers: true).first.
csv = CSV.read('data.csv', col_sep: "\t", encoding: "ISO8859-1", headers: true).first
csv = CSV.read('data.csv', col_sep: "\t", encoding: "ISO8859-1", headers: true)
cd csv.first
ls
fields
fields.count
cd ..
cd /
CSV.read('data.csv', encoding: "ISO8859-1", headers: true).first.fields.count
CSV.read('data.csv', col_sep: "\t", encoding: "ISO8859-1", headers: true).headers.fields.count
CSV.read('data.csv', col_sep: "\t", encoding: "ISO8859-1", headers: true).headers.count
CSV.read('data.csv', encoding: "ISO8859-1", headers: true).headers.count
CSV.read('data.csv', encoding: "ISO8859-1", headers: true).headers
CSV.read('test.tsv', encoding: "ISO8859-1", headers: true).headers
CSV.read('test.tsv', col_sep: "\t", encoding: "ISO8859-1", headers: true).headers
CSV.read('test.csv', col_sep: "\t", encoding: "ISO8859-1", headers: true).headers
CSV.read('test.csv', col_sep: "\t", headers: true).headers
CSV.read('test.csv', headers: true).headers
CSV.read('data.csv', encoding: "ISO8859-1", headers: true).headers
CSV.read('data.csv', col_sep: "\t", encoding: "ISO8859-1", headers: true).headers
CSV.read('data.csv', col_sep: "\t", encoding: "ISO8859-1").headers
CSV.read('data.csv', col_sep: "\t", encoding: "ISO8859-1").first.count

# télécharger fichier
# fix guillemets
File.new('data_fixed.csv', 'w').write(File.read('data.csv').force_encoding("ISO8859-1").gsub(/"/, "'"))
# tester chaque séparateur (si > 1 champs)
CSV.read('data_fixed.csv', col_sep: "\t", encoding: "ISO8859-1").count
# lire avec séparateur
csv = CSV.read('data_fixed.csv', col_sep: SEPARATEUR, encoding: "ISO8859-1").
csv.map { |r| r.to_hash).to_json
# envoi au client
JSON.parse(csv.map { |r| r.to_hash }.to_json)
